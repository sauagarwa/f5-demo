version: 1
logging:
  level: info
  context:
    - time
    - level
    - msg
    - route
    - request_id
    - details
    - error
  output_handler:
    type: console
    config:
      format: text
      stream: stderr
server:
  address: :4141

routes:
  - path: /demo-endpoint/v1/chat/completions
    policy: demo-policy     # Maps a route to policy
    schema: v1/chat_completions   # Use the AI Gateway common schema for requests
  - path: /demo-endpoint/v1/models
    policy: demo-model-policy     # Maps a route to policy
    schema: v1/models   # Use the AI Gateway common schema for requests

policies:
  - name: demo-policy
    profiles:
      - name: demo-profile  # Maps a policy to a profile
  - name: demo-model-policy
    profiles:
      - name: demo-model-profile  # Maps a policy to a profile

profiles:
  - name: demo-model-profile
    models:
      - name: meta-llama/Llama-3.2-3B-Instruct
    services:
      - name: demo-model-profile-model # Sends traffic to the OpenAI API
        selector:
          type: input.model
          values:
            - meta-llama/Llama-3.2-3B-Instruct 
      
  - name: demo-profile
    inputStages:
      - name: protect
        steps:
          - name: prompt-injection
      - name: analyze
        steps:
          - name: language-id
      # - name: set-system-prompt
      #   steps:
      #     - name: system-prompt
    responseStages:
      - name: repetition-detect
        steps:
          - name: repetition-detect
    services:
      - name: openshift-ai-1b-instruct # Sends traffic to the OpenAI API
        selector:
          tags:
            - language:es
            - language:fr
      - name: openshift-ai-3b-instruct # Sends traffic to the OpenAI API
        selector:
          tags:
            - language:en
services:
  - name: demo-model-profile-model
    type: meta-llama/Llama-3.2-3B-Instruct
    executor: openai
    config:
      endpoint: "http://llama-3-2-3b-instruct-predictor.f5-demo.svc.cluster.local:8080/v1/models"
  - name: openshift-ai-3b-instruct
    type: meta-llama/Llama-3.2-3B-Instruct
    executor: openai
    config:
      endpoint: "http://llama-3-2-3b-instruct-predictor.f5-demo.svc.cluster.local:8080/v1/chat/completions"
  - name: openshift-ai-1b-instruct
    type: RedHatAI/Llama-3.2-1B-Instruct-quantized.w8a8
    executor: openai
    config:
      endpoint: "http://llama-3-2-1b-instruct-quantized-predictor.f5-demo.svc.cluster.local:8080/v1/chat/completions"
processors:
  - name: system-prompt
    type: external
    config:
      # Your endpoint may differ
      endpoint: http://aigw-processors-f5.ai-gateway.svc.cluster.local
      version: 1
      namespace: f5
    params:
      modify: true
      strip_existing: true
      rules:
        - |
          You are a helpful AI Assistant designed to help users with questions about
          helping users set up AI-assisted workflows. Only answer questions about
          the topic of creating AI-assisted workflows.

  - name: prompt-injection
    type: external
    config:
      endpoint: http://aigw-processors-f5.ai-gateway.svc.cluster.local
      namespace: f5
      version: 1
    params:
      reject: true
      threshold: 0.95

  - name: repetition-detect
    type: external
    config:
      endpoint: http://aigw-processors-f5.ai-gateway.svc.cluster.local
      namespace: f5
      version: 1
    params:
      reject: true
      threshold: 0.95
  - name: language-id
    type: external
    config:
      endpoint: http://aigw-processors-f5.ai-gateway.svc.cluster.local
      namespace: f5
      version: 1